{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9a217d-bf75-4ddb-9c41-45a120c201eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import tqdm\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import (\n",
    "    ViTForImageClassification,\n",
    "    ViTImageProcessor,\n",
    ")\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor, Resize\n",
    "# import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03e0aa0c-0f2e-4f7d-aed7-63b828f682de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FAST_classificator import ClassificatorONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708173e6-a63d-465d-9f0c-79896022848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.id2label = {k: v for k, v in enumerate(sorted(os.listdir(root_dir)))}\n",
    "        self.label2id = {v: k for k, v in self.id2label.items()}\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.improcessor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "        \n",
    "        self.size = self.improcessor.size[\"height\"]\n",
    "        self.normalize = Normalize(\n",
    "            mean=self.improcessor.image_mean,\n",
    "            std=self.improcessor.image_std\n",
    "        )\n",
    "\n",
    "        self._transforms = Compose([\n",
    "            Resize((self.size, self.size)),\n",
    "            ToTensor(),\n",
    "            self.normalize\n",
    "        ])\n",
    "\n",
    "        for cls in self.id2label.values():\n",
    "            cls_folder = os.path.join(root_dir, cls)\n",
    "            if os.path.isdir(cls_folder):\n",
    "                for img_name in os.listdir(cls_folder):\n",
    "                    img_path = os.path.join(cls_folder, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(cls)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"pixel_values\": self.improcessor(\n",
    "                images=Image.open(self.image_paths[idx]).convert(\"RGB\")).pixel_values[0].squeeze(), # .squeeze()\n",
    "            \"labels\": self.label2id[self.labels[idx]]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55a19a-e46b-4576-a75c-bc8332fd164a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963b544f-1d73-4e8c-8798-62f3a73e662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset = CustomImageDataset(root_dir=\"/home/user1/hack/train_data_rkn/dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b9b6be-6574-43c1-a12a-3059680fe718",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ClassificatorONNX(\"vit_v4.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51cb70e2-6fbc-4187-9cbf-967e9822f567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(6), np.float32(0.86374795))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba_class(Image.open(dataset.image_paths[1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b3433-085a-498d-9236-29ddeb5f4f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cccb5d-5f92-4f7f-abf4-4a1be49b6fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
